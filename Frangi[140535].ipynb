{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oaJqSc0GaWAz"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-91cabab2d272>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "from skimage import io\n",
        "from skimage.filters import frangi\n",
        "from PIL import ImageFilter\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, csv_file, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.dataframe = pd.read_csv(csv_file)\n",
        "        self.classes = self.dataframe.iloc[:, 1].unique()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "    # ...\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx, 0] + '.jpg')\n",
        "\n",
        "        image = Image.open(img_name)  # Use PIL.Image.open\n",
        "        image = image.resize((64, 64))  # Resize the image\n",
        "\n",
        "        image = np.array(image)  # Convert the image to a numpy array\n",
        "\n",
        "        # Check the dimensions of the image\n",
        "        if len(image.shape) < 2 or len(image.shape) > 3:\n",
        "            print(f\"Invalid image dimensions for image {img_name}: {image.shape}\")\n",
        "            return\n",
        "\n",
        "        # Convert to grayscale if necessary\n",
        "        if len(image.shape) == 3 and image.shape[2] > 1:\n",
        "            image = rgb2gray(image)  # RGB to grayscale\n",
        "\n",
        "        # Apply the Frangi Vessel filter\n",
        "        image = frangi(image)\n",
        "\n",
        "        image = (image * 255).astype(np.uint8)  # Convert to uint8\n",
        "        image = Image.fromarray(image)\n",
        "        label = self.dataframe.iloc[idx, 1]\n",
        "        label = int(label)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths to datasets\n",
        "train_dir = '/content/drive/MyDrive/Disease_Grading/Training_Set'\n",
        "test_dir = '/content/drive/MyDrive/Disease_Grading/Testing_Set'\n",
        "train_csv = '/content/drive/MyDrive/Disease_Grading/Training_Labels.csv'\n",
        "test_csv = '/content/drive/MyDrive/Disease_Grading/Testing_Labels.csv'\n",
        "\n",
        "# Define transforms with data augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Create datasets and data loaders\n",
        "trainset = CustomImageDataset(train_dir, train_csv, transform=transform)\n",
        "testset = CustomImageDataset(test_dir, test_csv, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Enable anomaly detection\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "\n",
        "#CALL YOUR MODEL HERE\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(model.parameters())\n",
        "\n",
        "# Train the model\n",
        "n_epochs = 30\n",
        "for epoch in range(n_epochs):\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images)\n",
        "\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Compute training accuracy\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    average_loss = total_loss / len(trainloader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} / {n_epochs} : Loss {average_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
